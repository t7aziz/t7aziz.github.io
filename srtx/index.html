<head>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/styles/main.css">
</head>
<body>
<div id="app">
<header>
    <nav>
        <a href="mailto:aziztaha082@gmail.com">Email↗</a>
        <a href="/resume/resume.pdf" target="_blank">Resume↗</a>
        <a href="https://linkedin.com/in/t7aziz" target="_blank">LinkedIn↗</a>
        <a href="https://github.com/t7aziz" target="_blank">GitHub↗</a>
    </nav>
</header>
<section>
    <br>
    <a href="/" data-route>← Back</a>
    <br><h1>Sheertex</h1>
    <h3 id="-automating-textile-quality-assurance-with-machine-vision"><strong>Automating Textile Quality Assurance with Machine Vision</strong></h3>
<p>At Sheertex, I led the development of a <strong>machine vision system</strong> to automate quality assurance (QA) for our proprietary textile material. The goal was to reduce the <strong>cost to produce (CTP)</strong> by identifying defects in real time, ensuring only high-quality products reached packaging. I implemented and designed an image processing pipeline using <strong>OpenCV</strong>, integrating <strong>Keyence cameras</strong> and <strong>PLCs</strong>, and optimizing for low false positives. </p>
<hr>
<h3 id="-the-problem-manual-qa-and-defect-variability-"><strong>The Problem: Manual QA and Defect Variability</strong></h3>
<p>The textile manufacturing process at Sheertex produced materials with several types of defects:</p>
<ul>
<li><strong>Holes</strong>: Circular gaps in the material with clear edges and color contrast.</li>
<li><strong>Needle Lines</strong>: Long vertical lines with small threads of material across them.</li>
<li><strong>Barre</strong>: Repetitive horizontal stripe patterns, often subtle and hard to detect due to low contrast.</li>
<li><strong>Other Defects</strong>: Smaller line defects or irregularities.</li>
</ul>
<p>Manual QA to detect these defects was expensive and error-prone. </p>
<hr>
<h3 id="-the-solution-a-traditional-image-processing-pipeline-"><strong>The Solution: A Traditional Image Processing Pipeline</strong></h3>
<h4 id="-1-system-architecture-and-integration-"><strong>1. System Architecture and Integration</strong></h4>
<p>The machine vision system consisted of several hardware and software components, integrated into a cohesive workflow:</p>
<p>Keyence Camera → Keyence Vision Controller → Ethernet (Keyence SDK) → IPC (OpenCV Program) → Ethernet (Modbus TCP) → PLC → Pneumatic Pusher</p>
<ol>
<li><p><strong>Keyence Camera and Lighting</strong>:</p>
<ul>
<li>A <strong>Keyence CV-X camera</strong> captures high-resolution images of the textile material as it moved through the production line. The camera plugs into the vision controller via the High Speed Camera Cable, which plugs into the IPC via Ethernet</li>
<li><strong>Keyence lights</strong> were installed above the material to ensure consistent illumination and reduce shadows.</li>
<li><strong>3D printed brackets</strong> were CADed and printed with our printers and installed on our machines to position and hold the camera and lights correctly.</li>
</ul>
</li>
<li><p><strong>Industrial PC (IPC)</strong>:</p>
<ul>
<li>The camera connected to the IPC via Ethernet using Keyence’s proprietary SDK. The IPC ran the machine vision program, which processed the images and determined whether defects were present.</li>
</ul>
</li>
<li><p><strong>Programmable Logic Controller (PLC)</strong>:</p>
<ul>
<li>The IPC transmitted the defect classification results to the PLC over Ethernet. The PLC controlled a <strong>pneumatic pusher</strong> to sort the material into &quot;defect&quot; or &quot;no defect&quot; categories.
</li>
</ul>
</li>
</ol>
<h4 id="-2-image-processing-pipeline-"><strong>2. Image Processing Pipeline</strong></h4>
<p>The image processing pipeline was designed to detect defects with high accuracy while minimizing computational overhead. It consisted of four stages: <strong>preprocessing</strong>, <strong>defect detection</strong>, <strong>postprocessing</strong>, and <strong>integration</strong>. Following are also some sample OpenCV code snippets that were used in the final program.</p>
<ol>
<li><p><strong>Preprocessing</strong>:</p>
<ul>
<li><p><strong>Image Acquisition</strong>: The Keyence SDK was used to capture images from the camera.</p>
</li>
<li><p><strong>Image Enhancement</strong>: Images were converted to grayscale and normalized to improve contrast, for example:</p>
<pre><code>import cv2
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
normalized_image = cv2.normalize(gray_image, None, 0, 255, cv2.NORM_MINMAX)</code></pre>
</li>
</ul>
</li>
<li><p><strong>Defect Detection</strong>:</p>
<ul>
<li><p><strong>Holes</strong>: Detected using <strong>contour analysis</strong> and <strong>circular Hough transforms</strong>:</p>
<pre><code>edges = cv2.Canny(normalized<em>image, 100, 200)
contours, </em> = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
holes = [cnt for cnt in contours if cv2.contourArea(cnt) &gt; threshold]
</code></pre>
</li>
<li><p><strong>Needle Lines</strong>: Detected using <strong>line detection algorithms</strong> like the <strong>Hough Line Transform</strong>:</p>
<pre><code>lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=100, maxLineGap=10)</code></pre>
</li>
<li><p><strong>Barre</strong>: Detected using <strong>Fourier Transform</strong> to identify repetitive patterns:</p>
<pre><code>f_transform = np.fft.fft2(normalized_image)
f_shift = np.fft.fftshift(f_transform)
magnitude_spectrum = 20 * np.log(np.abs(f_shift))</code></pre>
</li>
</ul>
</li>
<li><p><strong>Postprocessing</strong>:</p>
<ul>
<li><p><strong>False Positive Reduction</strong>: Applied morphological operations to remove noise:</p>
<pre><code>kernel = np.ones((5, 5), np.uint8)
cleaned_image = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)</code></pre>
</li>
<li><p><strong>Defect Classification</strong>: Used a rule-based approach to classify defects based on size, shape, and other metrics capturing in previous steps</p>
</li>
</ul>
</li>
</ol>
<h4 id="-3-integration-"><strong>3. Integration</strong></h4>
<ol>
<li><p><strong>PLC Communication</strong>: The IPC sent defect classification results to the PLC using <strong>Modbus TCP</strong>:</p>
<pre><code>from pyModbusTCP.client import ModbusClient
client = ModbusClient(host=&quot;PLC_IP&quot;, port=502)
client.write_single_register(0, defect_flag)  # 0: No defect, 1: Defect</code></pre>
</li>
<li><p><strong>PLC Code</strong>:
 The PLC was programmed using <strong>ladder logic</strong>, a graphical programming language commonly used in industrial automation. The PLC received a binary signal from the IPC over <strong>Modbus TCP</strong>, indicating whether a defect was detected (<code>1</code> for defect, <code>0</code> for no defect). Example ladder logic:
</p>
<pre><code>IF DEFECT_FLAG == 1 THEN
    ACTIVATE(<span class="hljs-name">PNEUMATIC_PUSHER</span>)
ELSE
    DEACTIVATE(<span class="hljs-name">PNEUMATIC_PUSHER</span>)
END_IF
</code></pre>
<li><p><strong>Latency and Timing Considerations</strong>:
Cycle Time: The PLC was programmed to process signals and activate the pneumatic pusher within <strong>100 milliseconds</strong> to keep up with the production line speed.</p>
</li>
</ul>
</li>
</ol>
<h4 id="-4-evaluation-and-statistical-analysis-"><strong>4. Evaluation and Statistical Analysis</strong></h4>
<p>The total processing time of the system was roughly 600ms on average, which was fast enough to prevent causing delays on the manufacturing line as there is about 1 unit processed every 2000 ms. The rest of the engineering team assisted with the time analysis of the entire manufacturing process. </p>
<p>To evaluate the system’s effectiveness, I used statistical methods to measure <strong>false positive rates (FPR)</strong> and <strong>false negative rates (FNR)</strong>, relying on the manual QA team to evaluate false/trueness:</p>
<p><strong>Calculated statistics:</strong> 
Confusion matrix:</p>
<table>
<thead>
<tr>
<th></th>
<th><strong>&nbsp;&nbsp;&nbsp;Predicted Defect</strong></th>
<th><strong>&nbsp;&nbsp;&nbsp;Predicted No Defect</strong></th>
<th><strong>&nbsp;&nbsp;&nbsp;Total</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Actual Defect</strong></td>
<td>&nbsp;&nbsp;&nbsp;88</td>
<td>&nbsp;&nbsp;&nbsp;4</td>
<td>&nbsp;&nbsp;&nbsp;92</td>
</tr>
<tr>
<td><strong>Actual No Defect</strong></td>
<td>&nbsp;&nbsp;&nbsp;3</td>
<td>&nbsp;&nbsp;&nbsp;155</td>
<td>&nbsp;&nbsp;&nbsp;158</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td>&nbsp;&nbsp;&nbsp;91</td>
<td>&nbsp;&nbsp;&nbsp;159</td>
<td>&nbsp;&nbsp;&nbsp;250</td>
</tr>
</tbody>
</table>
<p><strong>Precision</strong>:
Precision measures how many of the predicted defects are actual defects: <strong>96.70%</strong>
<br><strong>Recall (Sensitivity)</strong>:
Recall measures how many of the actual defects are correctly predicted: <strong>95.65%</strong>.
<br><strong>F1-Score</strong>:
F1-Score is the harmonic mean of precision and recall, balancing the two metrics: <strong>96.17%</strong>.
<br><strong>False Negative Rate (FNR)</strong>:
FNR measures the proportion of actual defects that were incorrectly predicted as &quot;no defect.&quot;:<strong>4.35%</strong>.
<br><strong>False Positive Rate (FPR)</strong>:
FPR measures the proportion of actual non-defects that were incorrectly predicted as &quot;defect.&quot;: <strong>1.90%</strong>.</p>
<hr>
<h3 id="-interpretation-of-results-"><strong>Interpretation of Results</strong></h3>
<ul>
<li><p><strong>High Precision (96.70%)</strong>: The system has a <strong>96.70% accuracy</strong> in predicting defects, meaning very few non-defective products are flagged as defective.</p>
</li>
<li><p><strong>High Recall (95.65%)</strong>: The system correctly identifies <strong>95.65% of all defects</strong>, which is excellent given the priority on minimizing false negatives.</p>
</li>
<li><p><strong>Very Low FPR (1.90%)</strong>: The system has a <strong>1.90% false positive rate</strong>, meaning a very small percentage of non-defective products are incorrectly flagged as defective. This is an excellent result, as it minimizes the burden on the manual QA team.</p>
</li>
<li><p><strong>Prioritizing FNR over FPR</strong>: The system is tuned to minimize false negatives, ensuring that almost all defective products are caught. This results in an extremely low false positive rate, which is ideal for reducing the workload on the manual QA team.</p>
</li>
</ul>
<hr>
<h3 id="-challenges-and-root-cause-analysis-"><strong>Challenges and Root Cause Analysis</strong></h3>
<p>One of the biggest challenges was detecting <strong>barre defects</strong>, which were subtle and often missed by initial algorithms. Through <strong>root cause analysis</strong>, I identified that the issue was due to <strong>low contrast</strong> and <strong>noise</strong> in the images.</p>
<ul>
<li><p><strong>Solution</strong>: I implemented <strong>adaptive thresholding</strong>, for example:</p>
<pre><code>adaptive_thresh = cv2.adaptiveThreshold(normalized_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
</code></pre>
</li>
</ul>
<hr>
<h3 id="-impact-and-takeaways-"><strong>Impact and Takeaways</strong></h3>
<p>The machine vision system delivered significant improvements:</p>
<ul>
<li><p><strong>75% Reduction in Manual QA Time</strong>: Automated defect detection reduced the workload on the QA team.</p>
</li>
<li><p><strong>High Accuracy</strong>: Achieved a <strong>95% recall rate</strong> for critical defects, ensuring minimal false negatives.</p>
</li>
<li><p><strong>Seamless Integration</strong>: The system was fully integrated into the production line, with minimal disruption to existing processes.</p>
</li>
</ul>
<p>This project demonstrated the power of <strong>traditional image processing</strong> in manufacturing applications and the importance of <strong>root cause analysis</strong> and <strong>statistical evaluation</strong> in developing reliable automation systems.</p>

</section>
<footer>
    <p>&copy; 2025 Taha Aziz</p>
</footer>
</div>
</body>